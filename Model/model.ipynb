{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression model for select the survivors of the titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.92</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Anderson, Mr. Harry</td>\n",
       "      <td>male</td>\n",
       "      <td>48.00</td>\n",
       "      <td>19952</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>E12</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Andrews, Miss. Kornelia Theodosia</td>\n",
       "      <td>female</td>\n",
       "      <td>63.00</td>\n",
       "      <td>13502</td>\n",
       "      <td>77.9583</td>\n",
       "      <td>D7</td>\n",
       "      <td>S</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Andrews, Mr. Thomas Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>39.00</td>\n",
       "      <td>112050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>A36</td>\n",
       "      <td>S</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Appleton, Mrs. Edward Dale (Charlotte Lamson)</td>\n",
       "      <td>female</td>\n",
       "      <td>53.00</td>\n",
       "      <td>11769</td>\n",
       "      <td>51.4792</td>\n",
       "      <td>C101</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Astor, Col. John Jacob</td>\n",
       "      <td>male</td>\n",
       "      <td>47.00</td>\n",
       "      <td>PC 17757</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>C62 C64</td>\n",
       "      <td>C</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "5       1         1                              Anderson, Mr. Harry    male   \n",
       "6       1         1                Andrews, Miss. Kornelia Theodosia  female   \n",
       "7       1         0                           Andrews, Mr. Thomas Jr    male   \n",
       "8       1         1    Appleton, Mrs. Edward Dale (Charlotte Lamson)  female   \n",
       "9       1         0                           Astor, Col. John Jacob    male   \n",
       "\n",
       "     age    ticket      fare    cabin embarked  boat  \n",
       "0  29.00     24160  211.3375       B5        S     2  \n",
       "1   0.92    113781  151.5500  C22 C26        S    11  \n",
       "2   2.00    113781  151.5500  C22 C26        S  1000  \n",
       "3  30.00    113781  151.5500  C22 C26        S  1001  \n",
       "4  25.00    113781  151.5500  C22 C26        S  1002  \n",
       "5  48.00     19952   26.5500      E12        S     3  \n",
       "6  63.00     13502   77.9583       D7        S    10  \n",
       "7  39.00    112050    0.0000      A36        S  1003  \n",
       "8  53.00     11769   51.4792     C101        S     D  \n",
       "9  47.00  PC 17757  227.5250  C62 C64        C  1005  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path='../Media/titanicdatacleaned.xlsx'\n",
    "\n",
    "dataset=pd.read_excel(dataset_path)\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['sex'])\n",
    "\n",
    "\n",
    "def fill_boolean_encoding(column):\n",
    "\n",
    "    dataset[column] = dataset[column].astype(int)\n",
    "\n",
    "\n",
    "#Second option\n",
    "# def fill_boolean_encoding(column):\n",
    "#     for i in range(dataset.shape[0]):\n",
    "#         if dataset.loc[i, column] == True:\n",
    "#             dataset.loc[i, column] = 1\n",
    "#         else:\n",
    "#             dataset.loc[i, column] = 0\n",
    "\n",
    "\n",
    "fill_boolean_encoding('sex_female')\n",
    "\n",
    "fill_boolean_encoding('sex_male')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['sex_male'], inplace=True)\n",
    "\n",
    "dataset=dataset.rename(columns={'sex_female':'gender'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>0.92</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>2.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>30.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>25.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>4.00</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Soholt, Mr. Peter Andreas Lauritz Andersen</td>\n",
       "      <td>19.00</td>\n",
       "      <td>348124</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>F G73</td>\n",
       "      <td>S</td>\n",
       "      <td>1749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Strom, Miss. Telma Matilda</td>\n",
       "      <td>2.00</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Strom, Mrs. Wilhelm (Elna Matilda Persson)</td>\n",
       "      <td>29.00</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Tobin, Mr. Roger</td>\n",
       "      <td>24.00</td>\n",
       "      <td>383121</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>F38</td>\n",
       "      <td>Q</td>\n",
       "      <td>1771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  survived                                             name    age  \\\n",
       "0         1         1                    Allen, Miss. Elisabeth Walton  29.00   \n",
       "1         1         1                   Allison, Master. Hudson Trevor   0.92   \n",
       "2         1         0                     Allison, Miss. Helen Loraine   2.00   \n",
       "3         1         0             Allison, Mr. Hudson Joshua Creighton  30.00   \n",
       "4         1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  25.00   \n",
       "..      ...       ...                                              ...    ...   \n",
       "287       3         1                  Sandstrom, Miss. Marguerite Rut   4.00   \n",
       "288       3         0       Soholt, Mr. Peter Andreas Lauritz Andersen  19.00   \n",
       "289       3         0                       Strom, Miss. Telma Matilda   2.00   \n",
       "290       3         0       Strom, Mrs. Wilhelm (Elna Matilda Persson)  29.00   \n",
       "291       3         0                                 Tobin, Mr. Roger  24.00   \n",
       "\n",
       "      ticket      fare    cabin embarked  boat  gender  \n",
       "0      24160  211.3375       B5        S     2       1  \n",
       "1     113781  151.5500  C22 C26        S    11       0  \n",
       "2     113781  151.5500  C22 C26        S  1000       1  \n",
       "3     113781  151.5500  C22 C26        S  1001       0  \n",
       "4     113781  151.5500  C22 C26        S  1002       1  \n",
       "..       ...       ...      ...      ...   ...     ...  \n",
       "287  PP 9549   16.7000       G6        S    13       1  \n",
       "288   348124    7.6500    F G73        S  1749       0  \n",
       "289   347054   10.4625       G6        S  1759       1  \n",
       "290   347054   10.4625       G6        S  1760       1  \n",
       "291   383121    7.7500      F38        Q  1771       0  \n",
       "\n",
       "[292 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gender column have 2 options , for the female 1 and the male 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cristian\\AppData\\Local\\Temp\\ipykernel_11876\\1416127295.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset[column].fillna(1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>0.92</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>2.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>30.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>1</td>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>25.00</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>1</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>4.00</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Soholt, Mr. Peter Andreas Lauritz Andersen</td>\n",
       "      <td>19.00</td>\n",
       "      <td>348124</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>F G73</td>\n",
       "      <td>1</td>\n",
       "      <td>1749</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Strom, Miss. Telma Matilda</td>\n",
       "      <td>2.00</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>1</td>\n",
       "      <td>1759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Strom, Mrs. Wilhelm (Elna Matilda Persson)</td>\n",
       "      <td>29.00</td>\n",
       "      <td>347054</td>\n",
       "      <td>10.4625</td>\n",
       "      <td>G6</td>\n",
       "      <td>1</td>\n",
       "      <td>1760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Tobin, Mr. Roger</td>\n",
       "      <td>24.00</td>\n",
       "      <td>383121</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>F38</td>\n",
       "      <td>3</td>\n",
       "      <td>1771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>292 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  survived                                             name    age  \\\n",
       "0         1         1                    Allen, Miss. Elisabeth Walton  29.00   \n",
       "1         1         1                   Allison, Master. Hudson Trevor   0.92   \n",
       "2         1         0                     Allison, Miss. Helen Loraine   2.00   \n",
       "3         1         0             Allison, Mr. Hudson Joshua Creighton  30.00   \n",
       "4         1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  25.00   \n",
       "..      ...       ...                                              ...    ...   \n",
       "287       3         1                  Sandstrom, Miss. Marguerite Rut   4.00   \n",
       "288       3         0       Soholt, Mr. Peter Andreas Lauritz Andersen  19.00   \n",
       "289       3         0                       Strom, Miss. Telma Matilda   2.00   \n",
       "290       3         0       Strom, Mrs. Wilhelm (Elna Matilda Persson)  29.00   \n",
       "291       3         0                                 Tobin, Mr. Roger  24.00   \n",
       "\n",
       "      ticket      fare    cabin  embarked  boat  gender  \n",
       "0      24160  211.3375       B5         1     2       1  \n",
       "1     113781  151.5500  C22 C26         1    11       0  \n",
       "2     113781  151.5500  C22 C26         1  1000       1  \n",
       "3     113781  151.5500  C22 C26         1  1001       0  \n",
       "4     113781  151.5500  C22 C26         1  1002       1  \n",
       "..       ...       ...      ...       ...   ...     ...  \n",
       "287  PP 9549   16.7000       G6         1    13       1  \n",
       "288   348124    7.6500    F G73         1  1749       0  \n",
       "289   347054   10.4625       G6         1  1759       1  \n",
       "290   347054   10.4625       G6         1  1760       1  \n",
       "291   383121    7.7500      F38         3  1771       0  \n",
       "\n",
       "[292 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['embarked'].value_counts()\n",
    "\n",
    "embarked_values={'S':1,\"C\":2,\"Q\":3}\n",
    "\n",
    "embarked_values = {'S': 1, 'C': 2, 'Q': 3}\n",
    "\n",
    "def fill_embarked(column):\n",
    "    dataset[column] = dataset[column].map(embarked_values)\n",
    "\n",
    "    dataset[column].fillna(1, inplace=True)\n",
    "    \n",
    "    dataset[column]=dataset[column].astype(int)\n",
    "\n",
    "fill_embarked('embarked')\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['age', 'fare', 'gender', 'embarked']].values\n",
    "\n",
    "Y=dataset['survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,random_state=42,shuffle=True,train_size=0.7)\n",
    "\n",
    "num_features = x_train.shape[1]\n",
    "\n",
    "num_labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=tf.constant(x_train,dtype=tf.float32)\n",
    "\n",
    "x_test=tf.constant(x_test,dtype=tf.float32)\n",
    "\n",
    "\n",
    "y_train=tf.constant(y_train,dtype=tf.float32)\n",
    "\n",
    "y_test=tf.constant(y_test,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = tf.Variable(tf.random.normal([num_features, num_labels]))\n",
    "bias = tf.Variable(tf.zeros([num_labels]))\n",
    "\n",
    "def logistic_regression(x):\n",
    "    z = tf.matmul(x, weight) + bias\n",
    "    return tf.nn.sigmoid(z)\n",
    "\n",
    "# Ensure that y_train and y_test are (batch_size, 1)\n",
    "y_train = tf.reshape(y_train, [-1, 1])\n",
    "y_test = tf.reshape(y_test, [-1, 1])\n",
    "\n",
    "num_epochs=500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization (RMSprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristian\\Documents\\TitanicSurvivors\\venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    predicted = tf.round(y_pred)\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(predicted, y_true), tf.float32))\n",
    "    return acc\n",
    "\n",
    "mean = tf.reduce_mean(x_train, axis=0)\n",
    "std = tf.math.reduce_std(x_train, axis=0)\n",
    "x_train_norm = (x_train - mean) / std\n",
    "x_test_norm = (x_test - mean) / std\n",
    "\n",
    "learning_rate = 0.001  \n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate, decay=1e-6, momentum=0.9)\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "def run_optimization(x, y):\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = logistic_regression(x)\n",
    "        loss = loss_object(y, pred)\n",
    "    \n",
    "    gradients = g.gradient(loss, [weight, bias])\n",
    "        # Add gradient clipping to prevent explosion  gradients\n",
    "    optimizer.apply_gradients(zip(gradients, [weight, bias]))\n",
    "    \n",
    "    return loss, pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight norm: 1.4448\n",
      "Bias value: 0.0032\n",
      "Epoch 1/500 - loss: 1.0065 - acc: 0.4657 - val_loss: 0.8511 - val_acc: 0.5227\n",
      "Epoch 11/500 - loss: 0.9300 - acc: 0.4657 - val_loss: 0.7968 - val_acc: 0.5114\n",
      "Epoch 21/500 - loss: 0.8380 - acc: 0.4853 - val_loss: 0.7402 - val_acc: 0.5455\n",
      "Epoch 31/500 - loss: 0.7613 - acc: 0.4902 - val_loss: 0.6959 - val_acc: 0.5455\n",
      "Epoch 41/500 - loss: 0.6997 - acc: 0.5343 - val_loss: 0.6620 - val_acc: 0.5568\n",
      "Epoch 51/500 - loss: 0.6499 - acc: 0.5833 - val_loss: 0.6351 - val_acc: 0.6136\n",
      "Epoch 61/500 - loss: 0.6089 - acc: 0.6225 - val_loss: 0.6115 - val_acc: 0.6477\n",
      "Epoch 71/500 - loss: 0.5740 - acc: 0.6569 - val_loss: 0.5872 - val_acc: 0.6705\n",
      "Epoch 81/500 - loss: 0.5438 - acc: 0.6667 - val_loss: 0.5618 - val_acc: 0.6932\n",
      "Epoch 91/500 - loss: 0.5182 - acc: 0.7059 - val_loss: 0.5401 - val_acc: 0.6818\n",
      "Weight norm: 0.9741\n",
      "Bias value: 0.7690\n",
      "Epoch 101/500 - loss: 0.4967 - acc: 0.7500 - val_loss: 0.5248 - val_acc: 0.7045\n",
      "Epoch 111/500 - loss: 0.4787 - acc: 0.7647 - val_loss: 0.5128 - val_acc: 0.6932\n",
      "Epoch 121/500 - loss: 0.4641 - acc: 0.7843 - val_loss: 0.5034 - val_acc: 0.6932\n",
      "Epoch 131/500 - loss: 0.4523 - acc: 0.7990 - val_loss: 0.4960 - val_acc: 0.7273\n",
      "Epoch 141/500 - loss: 0.4432 - acc: 0.8088 - val_loss: 0.4907 - val_acc: 0.7273\n",
      "Epoch 151/500 - loss: 0.4362 - acc: 0.8137 - val_loss: 0.4872 - val_acc: 0.7159\n",
      "Epoch 161/500 - loss: 0.4312 - acc: 0.8137 - val_loss: 0.4853 - val_acc: 0.7159\n",
      "Epoch 171/500 - loss: 0.4277 - acc: 0.7941 - val_loss: 0.4846 - val_acc: 0.7159\n",
      "Epoch 181/500 - loss: 0.4255 - acc: 0.7892 - val_loss: 0.4849 - val_acc: 0.7273\n",
      "Epoch 191/500 - loss: 0.4242 - acc: 0.7892 - val_loss: 0.4857 - val_acc: 0.7386\n",
      "Weight norm: 1.6679\n",
      "Bias value: 1.1196\n",
      "Epoch 201/500 - loss: 0.4235 - acc: 0.7892 - val_loss: 0.4868 - val_acc: 0.7386\n",
      "Epoch 211/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4880 - val_acc: 0.7273\n",
      "Epoch 221/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4890 - val_acc: 0.7159\n",
      "Epoch 231/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4893 - val_acc: 0.7159\n",
      "Epoch 241/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 251/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4890 - val_acc: 0.7159\n",
      "Epoch 261/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 271/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4890 - val_acc: 0.7159\n",
      "Epoch 281/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 291/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4890 - val_acc: 0.7159\n",
      "Weight norm: 1.7623\n",
      "Bias value: 1.1803\n",
      "Epoch 301/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 311/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 321/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 331/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 341/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 351/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 361/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 371/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 381/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 391/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Weight norm: 1.7622\n",
      "Bias value: 1.1803\n",
      "Epoch 401/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 411/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 421/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 431/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 441/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 451/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 461/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 471/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 481/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n",
      "Epoch 491/500 - loss: 0.4231 - acc: 0.7892 - val_loss: 0.4891 - val_acc: 0.7159\n"
     ]
    }
   ],
   "source": [
    "def train_model(x_train, x_test, y_train, y_test, num_epochs):\n",
    "    # Normalize the data\n",
    "    mean = tf.reduce_mean(x_train, axis=0)\n",
    "    std = tf.math.reduce_std(x_train, axis=0)\n",
    "    x_train_norm = (x_train - mean) / std\n",
    "    x_test_norm = (x_test - mean) / std\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accuracies, val_accuracies = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Optimize the model\n",
    "        train_loss, train_pred = run_optimization(x_train_norm, y_train)\n",
    "        train_acc = accuracy(y_train, train_pred)\n",
    "\n",
    "        val_pred = logistic_regression(x_test_norm)\n",
    "        val_loss = loss_object(y_test, val_pred)\n",
    "        val_acc = accuracy(y_test, val_pred)\n",
    "\n",
    "        # 100 epochs analysis\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Weight norm: {tf.norm(weight).numpy():.4f}\")\n",
    "            print(f\"Bias value: {bias.numpy()[0]:.4f}\")\n",
    "\n",
    "        train_losses.append(float(train_loss))\n",
    "        val_losses.append(float(val_loss))\n",
    "        train_accuracies.append(float(train_acc))\n",
    "        val_accuracies.append(float(val_acc))\n",
    "\n",
    "        if epoch % 10 == 0:  # Reducir frecuencia de impresión\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "                  f\"loss: {train_loss:.4f} - acc: {train_acc:.4f} - \"\n",
    "                  f\"val_loss: {val_loss:.4f} - val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "\n",
    "resuls = train_model(x_train, x_test, y_train, y_test, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando fold 1/5\n",
      "Weight norm: 1.1611\n",
      "Bias value: 0.0032\n",
      "Epoch 1/500 - loss: 1.0395 - acc: 0.3865 - val_loss: 1.1188 - val_acc: 0.2683\n",
      "Epoch 11/500 - loss: 0.9673 - acc: 0.3926 - val_loss: 1.0007 - val_acc: 0.2927\n",
      "Epoch 21/500 - loss: 0.8820 - acc: 0.4172 - val_loss: 0.8744 - val_acc: 0.4146\n",
      "Epoch 31/500 - loss: 0.8100 - acc: 0.4663 - val_loss: 0.7731 - val_acc: 0.5366\n",
      "Epoch 41/500 - loss: 0.7496 - acc: 0.4969 - val_loss: 0.6933 - val_acc: 0.5854\n",
      "Epoch 51/500 - loss: 0.6993 - acc: 0.5644 - val_loss: 0.6265 - val_acc: 0.7073\n",
      "Epoch 61/500 - loss: 0.6571 - acc: 0.6196 - val_loss: 0.5676 - val_acc: 0.7561\n",
      "Epoch 71/500 - loss: 0.6215 - acc: 0.6196 - val_loss: 0.5200 - val_acc: 0.8049\n",
      "Epoch 81/500 - loss: 0.5911 - acc: 0.6442 - val_loss: 0.4817 - val_acc: 0.8293\n",
      "Epoch 91/500 - loss: 0.5648 - acc: 0.6380 - val_loss: 0.4515 - val_acc: 0.8049\n",
      "Weight norm: 0.6021\n",
      "Bias value: 0.5874\n",
      "Epoch 101/500 - loss: 0.5426 - acc: 0.6810 - val_loss: 0.4251 - val_acc: 0.8537\n",
      "Epoch 111/500 - loss: 0.5242 - acc: 0.7117 - val_loss: 0.3995 - val_acc: 0.8780\n",
      "Epoch 121/500 - loss: 0.5093 - acc: 0.7239 - val_loss: 0.3777 - val_acc: 0.9024\n",
      "Epoch 131/500 - loss: 0.4975 - acc: 0.7239 - val_loss: 0.3586 - val_acc: 0.8780\n",
      "Epoch 141/500 - loss: 0.4884 - acc: 0.7730 - val_loss: 0.3423 - val_acc: 0.9024\n",
      "Epoch 151/500 - loss: 0.4814 - acc: 0.7730 - val_loss: 0.3282 - val_acc: 0.9024\n",
      "Epoch 161/500 - loss: 0.4761 - acc: 0.7791 - val_loss: 0.3162 - val_acc: 0.8780\n",
      "Epoch 171/500 - loss: 0.4720 - acc: 0.7853 - val_loss: 0.3062 - val_acc: 0.8780\n",
      "Epoch 181/500 - loss: 0.4688 - acc: 0.7791 - val_loss: 0.2976 - val_acc: 0.8780\n",
      "Epoch 191/500 - loss: 0.4665 - acc: 0.7730 - val_loss: 0.2898 - val_acc: 0.8537\n",
      "Weight norm: 1.4194\n",
      "Bias value: 0.8648\n",
      "Epoch 201/500 - loss: 0.4650 - acc: 0.7730 - val_loss: 0.2830 - val_acc: 0.8780\n",
      "Epoch 211/500 - loss: 0.4641 - acc: 0.7791 - val_loss: 0.2774 - val_acc: 0.8780\n",
      "Epoch 221/500 - loss: 0.4637 - acc: 0.7669 - val_loss: 0.2731 - val_acc: 0.8780\n",
      "Epoch 231/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2702 - val_acc: 0.8780\n",
      "Epoch 241/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2693 - val_acc: 0.8780\n",
      "Epoch 251/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2700 - val_acc: 0.8780\n",
      "Epoch 261/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2704 - val_acc: 0.8780\n",
      "Epoch 271/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2700 - val_acc: 0.8780\n",
      "Epoch 281/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2702 - val_acc: 0.8780\n",
      "Epoch 291/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Weight norm: 1.5758\n",
      "Bias value: 0.9472\n",
      "Epoch 301/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 311/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 321/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 331/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 341/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 351/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 361/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 371/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 381/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 391/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Weight norm: 1.5757\n",
      "Bias value: 0.9472\n",
      "Epoch 401/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 411/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 421/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 431/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 441/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 451/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 461/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 471/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 481/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "Epoch 491/500 - loss: 0.4636 - acc: 0.7730 - val_loss: 0.2701 - val_acc: 0.8780\n",
      "\n",
      "Entrenando fold 2/5\n",
      "Weight norm: 1.9837\n",
      "Bias value: 0.0032\n",
      "Epoch 1/500 - loss: 0.7723 - acc: 0.5767 - val_loss: 0.6862 - val_acc: 0.6341\n",
      "Epoch 11/500 - loss: 0.7201 - acc: 0.5951 - val_loss: 0.6375 - val_acc: 0.6585\n",
      "Epoch 21/500 - loss: 0.6599 - acc: 0.6380 - val_loss: 0.5885 - val_acc: 0.7561\n",
      "Epoch 31/500 - loss: 0.6116 - acc: 0.6810 - val_loss: 0.5506 - val_acc: 0.7805\n",
      "Epoch 41/500 - loss: 0.5734 - acc: 0.7117 - val_loss: 0.5203 - val_acc: 0.8049\n",
      "Epoch 51/500 - loss: 0.5423 - acc: 0.7485 - val_loss: 0.4933 - val_acc: 0.8049\n",
      "Epoch 61/500 - loss: 0.5167 - acc: 0.7607 - val_loss: 0.4695 - val_acc: 0.8293\n",
      "Epoch 71/500 - loss: 0.4961 - acc: 0.7607 - val_loss: 0.4511 - val_acc: 0.8293\n",
      "Epoch 81/500 - loss: 0.4798 - acc: 0.7791 - val_loss: 0.4383 - val_acc: 0.8293\n",
      "Epoch 91/500 - loss: 0.4668 - acc: 0.7853 - val_loss: 0.4285 - val_acc: 0.8293\n",
      "Weight norm: 1.6170\n",
      "Bias value: 0.8931\n",
      "Epoch 101/500 - loss: 0.4563 - acc: 0.7791 - val_loss: 0.4235 - val_acc: 0.8293\n",
      "Epoch 111/500 - loss: 0.4475 - acc: 0.7730 - val_loss: 0.4230 - val_acc: 0.8049\n",
      "Epoch 121/500 - loss: 0.4403 - acc: 0.7791 - val_loss: 0.4257 - val_acc: 0.8293\n",
      "Epoch 131/500 - loss: 0.4345 - acc: 0.7791 - val_loss: 0.4289 - val_acc: 0.8293\n",
      "Epoch 141/500 - loss: 0.4302 - acc: 0.7853 - val_loss: 0.4319 - val_acc: 0.8049\n",
      "Epoch 151/500 - loss: 0.4269 - acc: 0.7791 - val_loss: 0.4361 - val_acc: 0.8049\n",
      "Epoch 161/500 - loss: 0.4247 - acc: 0.8037 - val_loss: 0.4399 - val_acc: 0.8049\n",
      "Epoch 171/500 - loss: 0.4232 - acc: 0.8037 - val_loss: 0.4434 - val_acc: 0.7805\n",
      "Epoch 181/500 - loss: 0.4225 - acc: 0.8037 - val_loss: 0.4464 - val_acc: 0.7561\n",
      "Epoch 191/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4494 - val_acc: 0.7317\n",
      "Weight norm: 1.8030\n",
      "Bias value: 1.2221\n",
      "Epoch 201/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4509 - val_acc: 0.7317\n",
      "Epoch 211/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4503 - val_acc: 0.7317\n",
      "Epoch 221/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4497 - val_acc: 0.7317\n",
      "Epoch 231/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4501 - val_acc: 0.7317\n",
      "Epoch 241/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4499 - val_acc: 0.7317\n",
      "Epoch 251/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4501 - val_acc: 0.7317\n",
      "Epoch 261/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 271/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 281/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 291/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Weight norm: 1.7985\n",
      "Bias value: 1.2203\n",
      "Epoch 301/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 311/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 321/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 331/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 341/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 351/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 361/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 371/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 381/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 391/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Weight norm: 1.7985\n",
      "Bias value: 1.2203\n",
      "Epoch 401/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 411/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 421/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 431/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 441/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 451/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 461/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 471/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 481/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "Epoch 491/500 - loss: 0.4222 - acc: 0.8037 - val_loss: 0.4500 - val_acc: 0.7317\n",
      "\n",
      "Entrenando fold 3/5\n",
      "Weight norm: 1.5986\n",
      "Bias value: 0.0032\n",
      "Epoch 1/500 - loss: 1.2815 - acc: 0.3988 - val_loss: 0.9472 - val_acc: 0.3902\n",
      "Epoch 11/500 - loss: 1.1896 - acc: 0.3988 - val_loss: 0.8879 - val_acc: 0.3902\n",
      "Epoch 21/500 - loss: 1.0739 - acc: 0.4110 - val_loss: 0.8228 - val_acc: 0.4146\n",
      "Epoch 31/500 - loss: 0.9719 - acc: 0.4233 - val_loss: 0.7686 - val_acc: 0.4146\n",
      "Epoch 41/500 - loss: 0.8857 - acc: 0.4540 - val_loss: 0.7245 - val_acc: 0.5366\n",
      "Epoch 51/500 - loss: 0.8138 - acc: 0.4724 - val_loss: 0.6885 - val_acc: 0.5610\n",
      "Epoch 61/500 - loss: 0.7540 - acc: 0.5215 - val_loss: 0.6589 - val_acc: 0.5610\n",
      "Epoch 71/500 - loss: 0.7044 - acc: 0.5460 - val_loss: 0.6341 - val_acc: 0.5854\n",
      "Epoch 81/500 - loss: 0.6629 - acc: 0.6074 - val_loss: 0.6125 - val_acc: 0.5854\n",
      "Epoch 91/500 - loss: 0.6274 - acc: 0.6380 - val_loss: 0.5924 - val_acc: 0.6341\n",
      "Weight norm: 0.4610\n",
      "Bias value: 0.6735\n",
      "Epoch 101/500 - loss: 0.5964 - acc: 0.6442 - val_loss: 0.5727 - val_acc: 0.6585\n",
      "Epoch 111/500 - loss: 0.5694 - acc: 0.6503 - val_loss: 0.5526 - val_acc: 0.6585\n",
      "Epoch 121/500 - loss: 0.5463 - acc: 0.6748 - val_loss: 0.5312 - val_acc: 0.7805\n",
      "Epoch 131/500 - loss: 0.5266 - acc: 0.7055 - val_loss: 0.5121 - val_acc: 0.8293\n",
      "Epoch 141/500 - loss: 0.5098 - acc: 0.7301 - val_loss: 0.4974 - val_acc: 0.8780\n",
      "Epoch 151/500 - loss: 0.4955 - acc: 0.7546 - val_loss: 0.4841 - val_acc: 0.8537\n",
      "Epoch 161/500 - loss: 0.4829 - acc: 0.7485 - val_loss: 0.4736 - val_acc: 0.8293\n",
      "Epoch 171/500 - loss: 0.4718 - acc: 0.7362 - val_loss: 0.4652 - val_acc: 0.7561\n",
      "Epoch 181/500 - loss: 0.4622 - acc: 0.7607 - val_loss: 0.4583 - val_acc: 0.8049\n",
      "Epoch 191/500 - loss: 0.4539 - acc: 0.7853 - val_loss: 0.4523 - val_acc: 0.7561\n",
      "Weight norm: 1.0984\n",
      "Bias value: 0.8223\n",
      "Epoch 201/500 - loss: 0.4469 - acc: 0.7975 - val_loss: 0.4479 - val_acc: 0.7317\n",
      "Epoch 211/500 - loss: 0.4411 - acc: 0.7975 - val_loss: 0.4445 - val_acc: 0.7561\n",
      "Epoch 221/500 - loss: 0.4364 - acc: 0.7975 - val_loss: 0.4423 - val_acc: 0.7317\n",
      "Epoch 231/500 - loss: 0.4326 - acc: 0.7975 - val_loss: 0.4410 - val_acc: 0.7317\n",
      "Epoch 241/500 - loss: 0.4298 - acc: 0.7975 - val_loss: 0.4404 - val_acc: 0.7317\n",
      "Epoch 251/500 - loss: 0.4278 - acc: 0.7975 - val_loss: 0.4405 - val_acc: 0.7317\n",
      "Epoch 261/500 - loss: 0.4264 - acc: 0.7975 - val_loss: 0.4411 - val_acc: 0.7317\n",
      "Epoch 271/500 - loss: 0.4256 - acc: 0.7975 - val_loss: 0.4420 - val_acc: 0.7317\n",
      "Epoch 281/500 - loss: 0.4253 - acc: 0.8037 - val_loss: 0.4430 - val_acc: 0.7317\n",
      "Epoch 291/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4438 - val_acc: 0.7317\n",
      "Weight norm: 1.7363\n",
      "Bias value: 1.1179\n",
      "Epoch 301/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4441 - val_acc: 0.7317\n",
      "Epoch 311/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 321/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4438 - val_acc: 0.7317\n",
      "Epoch 331/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 341/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4438 - val_acc: 0.7317\n",
      "Epoch 351/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 361/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 371/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 381/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 391/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Weight norm: 1.7249\n",
      "Bias value: 1.1111\n",
      "Epoch 401/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 411/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 421/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 431/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 441/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 451/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 461/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 471/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 481/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "Epoch 491/500 - loss: 0.4252 - acc: 0.8037 - val_loss: 0.4439 - val_acc: 0.7317\n",
      "\n",
      "Entrenando fold 4/5\n",
      "Weight norm: 1.1980\n",
      "Bias value: 0.0032\n",
      "Epoch 1/500 - loss: 1.0962 - acc: 0.2086 - val_loss: 0.9275 - val_acc: 0.3659\n",
      "Epoch 11/500 - loss: 1.0302 - acc: 0.2515 - val_loss: 0.9015 - val_acc: 0.3659\n",
      "Epoch 21/500 - loss: 0.9527 - acc: 0.3129 - val_loss: 0.8783 - val_acc: 0.3902\n",
      "Epoch 31/500 - loss: 0.8888 - acc: 0.3620 - val_loss: 0.8613 - val_acc: 0.4146\n",
      "Epoch 41/500 - loss: 0.8360 - acc: 0.4233 - val_loss: 0.8443 - val_acc: 0.4390\n",
      "Epoch 51/500 - loss: 0.7904 - acc: 0.4663 - val_loss: 0.8226 - val_acc: 0.4878\n",
      "Epoch 61/500 - loss: 0.7501 - acc: 0.5092 - val_loss: 0.7984 - val_acc: 0.5122\n",
      "Epoch 71/500 - loss: 0.7138 - acc: 0.5521 - val_loss: 0.7752 - val_acc: 0.5854\n",
      "Epoch 81/500 - loss: 0.6806 - acc: 0.5890 - val_loss: 0.7495 - val_acc: 0.5854\n",
      "Epoch 91/500 - loss: 0.6502 - acc: 0.6135 - val_loss: 0.7240 - val_acc: 0.6341\n",
      "Weight norm: 0.6893\n",
      "Bias value: 0.7378\n",
      "Epoch 101/500 - loss: 0.6219 - acc: 0.6810 - val_loss: 0.7015 - val_acc: 0.6585\n",
      "Epoch 111/500 - loss: 0.5954 - acc: 0.6871 - val_loss: 0.6789 - val_acc: 0.6585\n",
      "Epoch 121/500 - loss: 0.5706 - acc: 0.7239 - val_loss: 0.6580 - val_acc: 0.6829\n",
      "Epoch 131/500 - loss: 0.5477 - acc: 0.7301 - val_loss: 0.6410 - val_acc: 0.6829\n",
      "Epoch 141/500 - loss: 0.5266 - acc: 0.7117 - val_loss: 0.6257 - val_acc: 0.7073\n",
      "Epoch 151/500 - loss: 0.5073 - acc: 0.7239 - val_loss: 0.6128 - val_acc: 0.6829\n",
      "Epoch 161/500 - loss: 0.4897 - acc: 0.7362 - val_loss: 0.6016 - val_acc: 0.6829\n",
      "Epoch 171/500 - loss: 0.4737 - acc: 0.7485 - val_loss: 0.5925 - val_acc: 0.6585\n",
      "Epoch 181/500 - loss: 0.4594 - acc: 0.7853 - val_loss: 0.5852 - val_acc: 0.6585\n",
      "Epoch 191/500 - loss: 0.4466 - acc: 0.8037 - val_loss: 0.5796 - val_acc: 0.6341\n",
      "Weight norm: 0.9963\n",
      "Bias value: 0.8265\n",
      "Epoch 201/500 - loss: 0.4353 - acc: 0.8098 - val_loss: 0.5756 - val_acc: 0.6341\n",
      "Epoch 211/500 - loss: 0.4254 - acc: 0.8098 - val_loss: 0.5731 - val_acc: 0.6585\n",
      "Epoch 221/500 - loss: 0.4168 - acc: 0.8221 - val_loss: 0.5718 - val_acc: 0.6829\n",
      "Epoch 231/500 - loss: 0.4094 - acc: 0.8282 - val_loss: 0.5718 - val_acc: 0.7073\n",
      "Epoch 241/500 - loss: 0.4031 - acc: 0.8282 - val_loss: 0.5728 - val_acc: 0.7073\n",
      "Epoch 251/500 - loss: 0.3978 - acc: 0.8282 - val_loss: 0.5747 - val_acc: 0.7073\n",
      "Epoch 261/500 - loss: 0.3935 - acc: 0.8282 - val_loss: 0.5774 - val_acc: 0.7073\n",
      "Epoch 271/500 - loss: 0.3900 - acc: 0.8282 - val_loss: 0.5808 - val_acc: 0.7073\n",
      "Epoch 281/500 - loss: 0.3873 - acc: 0.8282 - val_loss: 0.5848 - val_acc: 0.7073\n",
      "Epoch 291/500 - loss: 0.3852 - acc: 0.8344 - val_loss: 0.5892 - val_acc: 0.7317\n",
      "Weight norm: 1.7733\n",
      "Bias value: 1.2108\n",
      "Epoch 301/500 - loss: 0.3837 - acc: 0.8405 - val_loss: 0.5938 - val_acc: 0.7317\n",
      "Epoch 311/500 - loss: 0.3828 - acc: 0.8405 - val_loss: 0.5984 - val_acc: 0.7317\n",
      "Epoch 321/500 - loss: 0.3822 - acc: 0.8405 - val_loss: 0.6029 - val_acc: 0.7317\n",
      "Epoch 331/500 - loss: 0.3820 - acc: 0.8405 - val_loss: 0.6069 - val_acc: 0.7317\n",
      "Epoch 341/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6097 - val_acc: 0.7317\n",
      "Epoch 351/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6106 - val_acc: 0.7073\n",
      "Epoch 361/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6100 - val_acc: 0.7317\n",
      "Epoch 371/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6095 - val_acc: 0.7317\n",
      "Epoch 381/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6099 - val_acc: 0.7317\n",
      "Epoch 391/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6097 - val_acc: 0.7317\n",
      "Weight norm: 1.9962\n",
      "Bias value: 1.3673\n",
      "Epoch 401/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 411/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 421/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 431/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 441/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 451/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 461/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 471/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 481/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "Epoch 491/500 - loss: 0.3819 - acc: 0.8344 - val_loss: 0.6098 - val_acc: 0.7317\n",
      "\n",
      "Entrenando fold 5/5\n",
      "Weight norm: 2.0965\n",
      "Bias value: 0.0032\n",
      "Epoch 1/500 - loss: 0.6784 - acc: 0.6707 - val_loss: 0.7106 - val_acc: 0.6250\n",
      "Epoch 11/500 - loss: 0.6362 - acc: 0.7134 - val_loss: 0.6745 - val_acc: 0.6500\n",
      "Epoch 21/500 - loss: 0.5872 - acc: 0.7378 - val_loss: 0.6363 - val_acc: 0.7000\n",
      "Epoch 31/500 - loss: 0.5468 - acc: 0.7378 - val_loss: 0.6033 - val_acc: 0.7000\n",
      "Epoch 41/500 - loss: 0.5141 - acc: 0.7439 - val_loss: 0.5756 - val_acc: 0.7250\n",
      "Epoch 51/500 - loss: 0.4877 - acc: 0.7561 - val_loss: 0.5549 - val_acc: 0.7500\n",
      "Epoch 61/500 - loss: 0.4665 - acc: 0.7683 - val_loss: 0.5388 - val_acc: 0.7500\n",
      "Epoch 71/500 - loss: 0.4496 - acc: 0.7683 - val_loss: 0.5262 - val_acc: 0.7500\n",
      "Epoch 81/500 - loss: 0.4365 - acc: 0.7744 - val_loss: 0.5168 - val_acc: 0.7500\n",
      "Epoch 91/500 - loss: 0.4263 - acc: 0.7805 - val_loss: 0.5099 - val_acc: 0.7500\n",
      "Weight norm: 1.7270\n",
      "Bias value: 0.9135\n",
      "Epoch 101/500 - loss: 0.4187 - acc: 0.7866 - val_loss: 0.5050 - val_acc: 0.7500\n",
      "Epoch 111/500 - loss: 0.4131 - acc: 0.7866 - val_loss: 0.5016 - val_acc: 0.7500\n",
      "Epoch 121/500 - loss: 0.4093 - acc: 0.7744 - val_loss: 0.4995 - val_acc: 0.7750\n",
      "Epoch 131/500 - loss: 0.4069 - acc: 0.7805 - val_loss: 0.4991 - val_acc: 0.7750\n",
      "Epoch 141/500 - loss: 0.4056 - acc: 0.7866 - val_loss: 0.5002 - val_acc: 0.7750\n",
      "Epoch 151/500 - loss: 0.4050 - acc: 0.7927 - val_loss: 0.5026 - val_acc: 0.7750\n",
      "Epoch 161/500 - loss: 0.4048 - acc: 0.7927 - val_loss: 0.5061 - val_acc: 0.7750\n",
      "Epoch 171/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 181/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5101 - val_acc: 0.7750\n",
      "Epoch 191/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5095 - val_acc: 0.7750\n",
      "Weight norm: 1.9000\n",
      "Bias value: 1.3634\n",
      "Epoch 201/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5091 - val_acc: 0.7750\n",
      "Epoch 211/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5094 - val_acc: 0.7750\n",
      "Epoch 221/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 231/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 241/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 251/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 261/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 271/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 281/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 291/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Weight norm: 1.9029\n",
      "Bias value: 1.3666\n",
      "Epoch 301/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 311/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 321/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 331/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 341/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 351/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 361/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 371/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 381/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 391/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Weight norm: 1.9029\n",
      "Bias value: 1.3666\n",
      "Epoch 401/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 411/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 421/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 431/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 441/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 451/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 461/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 471/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 481/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "Epoch 491/500 - loss: 0.4047 - acc: 0.7866 - val_loss: 0.5093 - val_acc: 0.7750\n",
      "\n",
      "Cross validation results\n",
      "Accuracy promedio: 0.7696 ± 0.0567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "def cross_validate_model(X, Y, num_epochs, k_folds=5):\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nEntrenando fold {fold+1}/{k_folds}\")\n",
    "        \n",
    "        # Prepare data\n",
    "        x_train_fold = tf.gather(X, train_idx)\n",
    "        y_train_fold = tf.gather(Y, train_idx)\n",
    "        x_val_fold = tf.gather(X, val_idx)\n",
    "        y_val_fold = tf.gather(Y, val_idx)\n",
    "        \n",
    "        # Reset the bias and weight\n",
    "        global weight, bias\n",
    "        weight.assign(tf.random.normal([num_features, num_labels]))\n",
    "        bias.assign(tf.zeros([num_labels]))\n",
    "        \n",
    "        # Train the model\n",
    "        results = train_model(x_train_fold, x_val_fold, \n",
    "                            y_train_fold, y_val_fold, \n",
    "                            num_epochs)\n",
    "        \n",
    "        fold_scores.append(results['val_accuracies'][-1])\n",
    "    \n",
    "    print(\"\\nCross validation results\")\n",
    "    print(f\"Accuracy promedio: {np.mean(fold_scores):.4f} ± {np.std(fold_scores):.4f}\")\n",
    "    \n",
    "    return fold_scores\n",
    "\n",
    "scores = cross_validate_model(x_train, y_train, num_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cristian\\Documents\\TitanicSurvivors\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, activation='sigmoid', input_shape=(num_features,))\n",
    "])\n",
    "\n",
    "model.layers[0].set_weights([weight.numpy(), bias.numpy()])\n",
    "\n",
    "model.save('titanic_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
